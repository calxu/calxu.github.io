<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Machine Learning on Travis, Xu</title>
    <link>https://calxu.github.io/tags/machine-learning/</link>
    <description>Recent content in Machine Learning on Travis, Xu</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 07 Oct 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://calxu.github.io/tags/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>机器学习笔记-KNN（统计学习方法-第3章）</title>
      <link>https://calxu.github.io/note/20201007_knn/</link>
      <pubDate>Wed, 07 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://calxu.github.io/note/20201007_knn/</guid>
      <description>最近在疏理《统计学习方法》中的知识点，方便自己后续复习。这里记录下第3章K近邻算法的基本思想。
K近邻（KNN）是一种基本分类与回归方法。给定目标样本通过K个邻居来决定目标样本的标签。K近邻法有三个基本要素：K值的选择、距离度量和分类回归决策规则。KNN并不需要训练，但需要遍历整个训练集，所以预测比较慢，书中提到用KD树进行优化，来提高K近邻搜索的效率。
K近邻基本要素 距离度量 KNN一般采用欧式距离，但更一般的是 $L_p$ 距离， $L_p$ 距离在机器学习中经常会看到。
设特征空间 $\chi$ 是 $n$ 维实数向量空间 $R^n$ ， $x_i, x_j \in \chi$ ， $x_i = (x_i^1, x_i^2, ..., x_i^n)^T$ ， $x_j = (x_j^1, x_j^2, ..., x_j^n)^T$ ， $x_i, x_j$ 的 $L_p$ 距离定义为 $L_p(x_i, x_j) = (\sum_{l=1}^n |x_i^l - x_j^l|^p) ^{\frac{1}{p}}$ ，其中 $p \geqslant 1$
当 $p = 1$ 时，称为曼哈顿距离，即 $L_1(x_i, x_j) = \sum_{l=1}^n |x_i^l - x_j^l|$ ；
当 $p = 2$ 时，称为欧式距离，即 $L_2(x_i, x_j) = (\sum_{l=1}^n |x_i^l - x_j^l|^2) ^{\frac{1}{2}}$ ，写成我们最熟悉的形式 $\sqrt{(\Delta x_1)^2 + (\Delta x_2)^2 + .</description>
    </item>
    
    <item>
      <title>机器学习笔记-神经网络（西瓜书第5章）</title>
      <link>https://calxu.github.io/note/20201003_neural_networks/</link>
      <pubDate>Fri, 02 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://calxu.github.io/note/20201003_neural_networks/</guid>
      <description>最近把周志华的《机器学习》西瓜书系统的复习一遍，整理一些笔记。主要介绍下神经网络的基本单元-神经元；其次介绍下常用的激活函数；经典BP算法的推导和深度学习的简述。
神经元简述 神经网络中最基本的单元是一直沿用至今的“M-P神经元”，神经元接收到来自 n 个其他神经元传递过来的输入信号，这些输入信号通过带权重的连接进行传递，神经元接收到的总输入值将与神经元的阈值进行比较，然后通过“激活函数”输出（图中 $f$ 即为激活函数）。
感知机是两层神经元组成，即输入层和输出层。它是最简单的神经网络，学习得是一个超平面，但其表达能力非常有限，例如“异或”问题它就表达学习不了。要解决这类问题，所以需要考虑多层功能的神经元。即利用感知机神经元构成多层神经网络。
常用激活函数 激活函数是上述神经元中的 $f$ 函数，这里介绍下常用的激活函数。
 阶跃函数：即 $f(x) = \left\{\begin{matrix} 1, &amp;amp; x \geqslant 0 &amp;amp; \\ 0, &amp;amp; x &amp;lt; 0 &amp;amp; \end{matrix}\right.$ ，优点：形式简单；缺点：梯度为0，不能用于反向传播过程。因为不可导，该激活函数不常用。
 sigmoid函数：即 $f(x) = \frac{1}{1 + e^{-x}} $ ， 它是一个logistic函数，优点：连续可微；缺点：函数在原点周围不对称，得到的值都是正的；梯度变化在[-3,3]外渐趋平坦。
 tanh函数：与sigmoid函数非常相似，即 $tanh(x) = 2 \cdot sigmoid(2x) - 1$ ，x轴方向把sigmoid压缩；y轴方向扩大1倍同时下移1个单位。优点：连续可导且关于原点对称；缺点：梯度变化在非[-3,3]区间内渐趋平坦（与sigmoid类似）。
 ReLU函数：即 $f(x) = \left\{\begin{matrix} x, &amp;amp; x \geqslant 0 &amp;amp; \\ 0, &amp;amp; x &amp;lt; 0 &amp;amp; \end{matrix}\right.</description>
    </item>
    
    <item>
      <title>机器学习笔记-感知机（SVM 和 神经网络的基础）</title>
      <link>https://calxu.github.io/note/20200926_ml_perceptron/</link>
      <pubDate>Sat, 26 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://calxu.github.io/note/20200926_ml_perceptron/</guid>
      <description>最近在复习机器学习的基础，学习下《统计学习方法》感知机这章，主要针对书上难以理解的部分做一些学习笔记，方便自己后期复习。
感知机是 二分类 的线性分类模型，输入为实例的特征向量，输出为实例的类别（取+1和-1）。感知机对应于输入空间中将实例划分为二类的分离超平面。感知机旨在求出该超平面，为求得超平面引入了基于误分类的损失函数，利用梯度下降法对损失函数进行最优化。
感知机1957年被提出，它是 神经网络模型 与 支持向量机（SVM） 的基础。
感知机模型定义 对于 $x \in R^n$ ，输出 $\{+1, -1\}$ ，表达形式为： $f(x) = sign(w \cdot x + b)$ ，即该式称为感知机。
其中，$sign(x) = \left\{\begin{matrix} +1, &amp;amp; x \geqslant 0 &amp;amp; \\ -1, &amp;amp; x &amp;lt; 0 &amp;amp; \end{matrix}\right.$
$sign$ 通常称之为激活函数，激活函数同时也是构成神经网络模型的基本单元，不过在神经网络模型中通常用 $sigmoid$ 函数。
几何含义即对应书上的超平面，如下图。
其实我们就是在学习参数 $w$ 和 $b$ ，确定了 $w$ 和 $b$ ，图上的直线（高维高间下为超平面）也就确定了，那么以后来一个数据点，就可以用训练好的模型进行预测，如果大于等于0就分到 +1，小于0就分到 -1。
 这里有个小知识点（大概是高中的几何数据）证明下，证明如下。
证明： $\overrightarrow{w}$ 是直线 $\overrightarrow{w} \cdot \overrightarrow{x} + b = 0$（高维空间下为超平面）的法向量。</description>
    </item>
    
    <item>
      <title>机器学习笔记-朴素贝叶斯法</title>
      <link>https://calxu.github.io/note/20200923_ml_bayes/</link>
      <pubDate>Wed, 23 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://calxu.github.io/note/20200923_ml_bayes/</guid>
      <description>最近在恶补统计学习方面的理论知识，结合《统计学习方法》和知乎一篇文章对朴素贝叶斯分类进行一次学习总结，方便自己后期复习。贝叶斯分类是一类分类算法的总称，这类算法均以贝叶斯定理为基础，故统称为贝叶斯分类。朴素贝叶斯分类是贝叶斯分类中最简单，也是常见的一种分类方法。
在看完《统计学习方法》书时，书上的数学公式整体上比较抽象，看得有点晦涩难懂。最好的方式还是先看书上例子或知乎上的例子，然后通过例子再理解数学公式。
知识点疏理 最核心的数学公式（即贝叶斯公式）： $P(X,Y)=P(X) \cdot P(Y|X) = P(Y) \cdot P(X|Y)$
化简下得： $P(Y|X) = \frac{P(Y) \cdot P(X|Y)}{P(X)}$
换种形式表述上式： $P(类别|特征) = \frac{P(类别) \cdot P(特征|类别)}{P(特征)}$
上式中 $P(类别)$ 是可以直接在训练集上求得，若将 $P(特征)$、$P(特征|类别)$ 看成在类确定的条件下特征是条件独立的， $P(特征)$、$P(特征|类别)$ 也可在训练集上容易求得。在求得等式右边后，就可以知道对应特征所属类别 $P(类别|特征)$ 的概率了。
计算两个注意点：
 $P(特征|类别) = P(特征1, 特征2, ...特征n|类别) = P(特征1|类别) \cdot P(特征2|类别) \cdot ... \cdot P(特征n|类别)$ ，只有当在类确定的条件下特征都是条件独立的，上式才成立。
 $P(特征)$ 的计算应该用贝叶斯全概率公式（看书这里一开始很费解），而非 $P(特征) \neq P(特征1) \cdot P(特征2) \cdot ... \cdot P(特征n)$ ，因为这里是前提假设是 特征条件独立而非特征独立，所以应该用贝叶斯全概率公式，即 $P(特征) = \underset{所有类别}{\sum} ( {P(类别) \cdot \underset {所有特征}{\prod}P(特征|类别) } )$ 。这里 $P(特征)$ 是个常数，所以在《统计学习方法》中将它省略而不影响最终类别的判断。</description>
    </item>
    
    <item>
      <title>机器学习笔记-逻辑斯谛回归与最大熵模型</title>
      <link>https://calxu.github.io/note/20200920_ml_lr/</link>
      <pubDate>Sun, 20 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://calxu.github.io/note/20200920_ml_lr/</guid>
      <description>学习了《统计学习方法》逻辑斯谛回归与最大熵模型这一章节，现在对这章节做一些笔记。逻辑斯谛回归是工业界非常常用的模型之一，它具有可解释性强、参数训练快等优点；但它和最大熵模型有什么关系，这里做一些笔记方便自己后面的复习。
首先介绍最大熵模型，它是一种模型选择的原则，它本身在工业界并不常用，但它的思想几乎是很多模型选择算法中都有体现；其次通过例子说明逻辑斯谛回归是最大熵模型的一个特例。
最大熵模型 最大熵模型通俗的解释就是按照模型熵最大的原则来选择模型，当我们预测一个随机变量时，最好假设它均匀分布，保留全部不确定性，此时预测的风险最小。举个例子：如果投掷一颗骰子，让你预测各面出现的概率，在没有任何额外信息的情况下，我们会认为骰子是均匀的，各面出现的概率为1/6，从直觉上说，这是最稳妥的策略。
以上的直觉告诉我们最大熵模型是最稳妥的策略，具体数学上如果迭代学习最大熵的模型呢？《统计学习方法》最大熵模型的学习给了我们数学上的推导，这里稍做下疏理，方便自己后面的复习理解：
最大熵模型是一个概率模型，目的是寻找符合要求的条件分布 $P(Y|X)$ 。在定义最大熵模型之前，需要引入下列概念：
联合分布的经验分布： $\tilde{P}(X=x,Y=y) = \frac{v(X=x,Y=y)}{N}$
边缘分布的经验分布： $\tilde{P}(X=x) = \frac{v(X=x)}{N}$
其中， $v(X=x,Y=y)$ 表示训练集中样本 $(x,y)$ 出现的频数， $v(X=x)$ 表示训练数据中输入 $x$ 出现的频数， $N$ 表示训练集样本数。
特征函数： $f(x,y)=\left\{\begin{matrix} 1, &amp;amp; x与y满足某一事实 &amp;amp; \\ 0, &amp;amp; 否则 &amp;amp; \\ \end{matrix}\right.$
此特征函数具有普遍性，因此得到“最大熵模型”的一般形式。 如果替换为某种特殊形式，可以得到“逻辑斯谛模型” 。
特征函数 $f$ 关于经验分布 $\tilde{P}(X,Y)$ 的期望值： $E_{\tilde{P}}(f) = \sum_{x,y} \tilde{P}(x,y)f(x,y)$
特征函数 $f$ 关于联合分布 $P(X,Y) = \tilde{P}(X)P(Y|X)$ 的期望值： $E_P(f) = \sum_{x,y} \tilde{P}(x)P(y|x) f(x,y)$
我们假设训练集对于模型的学习是有效的，使得 $E_{\tilde{P}}(x) = E_{P}(f)$ ，此时特征函数 $f$ 称为模型的约束条件。</description>
    </item>
    
    <item>
      <title>机器学习笔记-梯度下降法和牛顿法</title>
      <link>https://calxu.github.io/note/20200918_ml_iteration/</link>
      <pubDate>Fri, 18 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://calxu.github.io/note/20200918_ml_iteration/</guid>
      <description>机器学习中很多时候都是在求解无约束条件的最优化问题，比如：感知机、逻辑斯谛回归、条件随机场的求解。在求解无约束最优化问题最常用的两类方法是 梯度下降法 和 牛顿法，可参考《统计学习方法》的附录A 和 附录B。 这篇笔记记录下自己对两类方法的理解。
梯度下降法 在机器学习任务中，要求目标函数 $f(x)$ 的使其最小的 $x$ 的值。梯度下降是一种迭代算法，常用来求解这类问题。基本步骤为：选取初值；梯度方向不断迭代；更新 $x$ 的值找到最逼近的解。
 选取 $x^{k}$ ，计算 $f(x^{k})$ ，$k$ 初始值为0；
将 $f(x^{k+1})$ 在 $x^{k}$ 处一阶泰勒展开得： $f(x^{k+1}) = f(x^{k} + \Delta t) \approx f(x^{k}) + f&#39;(x^{k}) \Delta t$ ，按梯度方向不断迭代逼近可取 $\Delta t = - \lambda \cdot f&#39;(x^k)$ ，其中 $\lambda$ 为步长；
重复以上两步，直到迭代找出相应的 $x^{k+1}$ 为止，即 $||f(x^{(k+1)} - f(x^k) || &amp;lt; \epsilon$ ，停止迭代，令 $x=x^{k+1}$ ；
 个人理解：$\Delta t = - \lambda \cdot f&#39;(x^k)$ 这里的 $\lambda$ 为步长，可由一维搜索确定，但一般直接赋一个小的数即可；其中 $-f&#39;(x^k)$ 为负梯度方向，这里也可以取与 $-f&#39;(x^k)$ 正相关的数值；</description>
    </item>
    
    <item>
      <title>机器学习笔记-决策树</title>
      <link>https://calxu.github.io/note/20200206_ml_decision_tree/</link>
      <pubDate>Thu, 06 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://calxu.github.io/note/20200206_ml_decision_tree/</guid>
      <description>在工业界，决策树（Decision Tree）是一类常见的机器学习方法。决策树综合可解释性、表征能力（线性模型 &amp;lt; 树模型 &amp;lt; 神经网络）、可操作性（调参）等优点，目前它是工业界应用最广的模型，很多基于树模型的开源的框架可供选择，比如Random Forest、GBDT、XGBoost、LightGBM 这些工业界最为常用的框架都是以决策树模型为基础的。
决策树是一种基本的分类与回归方法。这篇笔记主要介绍决策树的基本流程；其次介绍决策树的特征选择；再介绍决策树的剪枝；然后介绍一个历史上非常经典的决策树CART树；最后再介绍决策树模型的其它要点。
决策树的基本流程 决策树学习本质上是从训练数据集中归纳出一组分类规则。从所有可能的决策树中选取最优决策树是NP完全问题，所以现实中决策树学习算法通常采用启发式方法（即贪心策略），近似求解这一最优化问题。这样得到的决策树是次最优的。
决策树的基本流程伪代码如下图所示（摘自《西瓜书》P74）。

决策树的生成是一个递归过程。在决策树基本算法中，有三种情形会导致递归返回：
情形1： 当前结点包含的样本全属于同一类别，无需划分；
情形2： 当前属性集为空，或是所有样本在所有属性上取值相同，无法划分；
情形3： 当前结点包含的样本集合为空，不能划分；
在情形2中，我们把当前结点标记为叶结点，并将其类别设定为该结点所含样本最多的类别；在情形3中，同样把当前结点标记为叶结点，但将其类别设定为其父结点所含样本最多的类别。注意这两种情形的处理实质不同：情形2是在利用当前结点的后验分布，而情形3则是把父结点的样本分布为当前结点的先验分布。
上图是决策树学习基本算法的流程，基本算法流程中重点在第8行，如何选择最优的划分特征，所以决策树学习算法生成过程包括特征选择。
决策树特征选择 决策树学习基本算法的关键是第8行，即特征选择，也就是如何选择最优划分属性。一般而言，随着划分过程不断进行，我们希望决策的分支结点所包含的样本尽可能属于同一类别，即结点的“纯度”越来越高。
树结点分叉后“纯度”变化的数学描述通常有信息增益、信息增益比和基尼指数，下面对这三者分别进行介绍。
信息增益 在讲信息增益之前必须要提“信息熵”。&amp;rdquo;信息熵&amp;rdquo;（information entropy）是度量样本集合纯度最常用的一种指标，假定当前样本集合 $D$ 中第 $k$ 类样本所占的比例为 $p_k (k=1,2,...,|Y|)$ ，则 $D$ 的信息熵定义为 $Ent(D)=-\sum_{k=1}^{|Y|} p_k \cdot log_2 p_k$ ， $Ent(D)$ 的值越小，则 $D$ 的纯度越高。
假定离散属性 $a$ 有 $V$ 个可能的取值 $\{a^1, a^2, ..., a^V\}$ ， 若使用 $a$ 来对样本集 $D$ 进行划分，则会产生 $V$ 个分支结点，其中第 $v$ 个分支结点包含了 $D$ 中所有在属性 $a$ 上取值为 $a^v$ 的样本记为 $D^v$ 。可以根据信息熵的定义计算出 $D^v$ 的信息熵，再考虑到不同的分支结点所包含的样本数不同，给分支结点赋予权重 $|D^v|/|D|$ ，即样本数越多的分支结点的影响越大，于是可计算出可用属生 $a$ 对样本集 $D$ 进行划分所获得的“信息增益”（information gain），即 $Gain(D, a)=Ent(D)-\sum_{v=1}^{V} \frac{D^v}{D} Ent(D^v)$ 。</description>
    </item>
    
    <item>
      <title>机器学习笔记-集成学习Boosting</title>
      <link>https://calxu.github.io/note/20200202_ml_boosting/</link>
      <pubDate>Sun, 02 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://calxu.github.io/note/20200202_ml_boosting/</guid>
      <description>根据基学习器的生成方式，目前集成学习方法主流分成两大类，即Boosting 和 Bagging。Boosting集成是每个基学习器存在强依赖关系，必须串行生成，目前比较有代表性的工业界框架有AdaBoost、GBDT、XGBoost 和 LightGBM，其中后三者工业界比较常用；Bagging集成是每个基学习器间不需要存在依赖关系、可并行化，其中比较具有代表性的是随机森林（即 Random Forest）。
这篇笔记主要记录集成学习Boosting的思想，关于Bagging的思想可参考上一篇笔记。这篇笔记首先记录Boosting的基本思路；其次详细记录经典且具有代表性的提升算法AdaBoost；然后记录基分类器为决策树的boosting集成树模型（boosting tree）；最后记录一种特殊的boosting集成方法即梯度提升（gradient boosting）。
Boosting方法的基本思路 Boosting方法基于的思想：对于一个复杂任务来说，将多个专家的判断进行适当的综合所得出的判断，要比其中任何一个专家单独的判断好，就是“三个臭皮匠顶个诸葛亮”的道理。在1990年，Schapire证明一个类强可学习与一个类弱可学习是等价的，即一个类是强可学习的充分必要条件是这个类是弱可学习的。
这样一来，如果已经发现了“弱学习算法”，那么能否将它提升为“强学习算法”。发现弱学习算法通常要比发现强学习算法容易得多，那么如何具体实施提升，便成为开发提升方法时所要解决的问题。经典的具有代表的提升方法是AdaBoost算法。
对于分类问题而言，给定一个训练样本集，求比较粗糙的分类规则（弱分类器）要比求精确的分类规则（强分类器）容易得多。Boosting集成就是从弱学习算法出发，反复学习，得到一系列弱分类器（又称基本分类器），然后组合这些弱分类器，构成一个强分类器。
AdaBoost AdaBoost（Adaptive Boosting）有自适应集成之意。对于AdaBoost而言，有两个重点：一是在每一轮如何改变训练数据的权值；二是如何将弱分类器组合成一个强分类器。关于第一个问题，AdaBoost的做法是，提高那些被前一轮弱分类器错误分类样本的权值，而降低那些被正确分类样本的权值，这样一来，那些没有得到正确分类的数据，由于其权值的加大而受到后一轮的弱分类器的更大关注，于是，分类问题被一系列的弱分类器“分而治之”。至于第二个问题，即弱分类器的组合，AdaBoost采取加权多数表决的方法，具体地，加大分类误差率小的弱分类器的权值，使其在表决中起较大的作用，减小分类误差率较大的弱分类器的权值，使其在表决中起较小的作用。AdaBoost的巧妙之处就在于它将这些想法自然且有效地实现在一种算法里。
AdaBoost算法描述 假设给定一个二类分类的训练数据集 $T=\{(x_1,y_1),(x_2,y_2),...,(x_N,y_N)\}$ 。其中，每个样本点由实例与标记组成。实例 $x_i \in X \subseteq R^n$ ，标记 $y_i \in Y=\{-1,+1\}$ ，$X$ 是实例空间，$Y$ 是标记集合。AdaBoost利用以下算法，从训练数据中学习一系列弱分类器，并将这些弱分类器线性组合成为一个强分类器。
AdaBoost算法描述 输入：训练集 $T=\{(x_1,y_1),(x_2,y_2),...,(x_N,y_N)\}$，其中 $x_i \in X \subseteq R^n$ ，标记 $y_i \in Y=\{-1,+1\}$ ；弱学习算法；
输出：最终分类器 $G(x)$；
(1) 初始化训练数据的权值分布 $D_1=\{w_{11},...,w_{1i},...,w_{1N}\}, w_{1i}=\frac{1}{N}, i=1,2,...,N$ 。
(2) 对 $m=1,2,...,M$
　(a) 使用具有权值分布 $D_{m}$ 的训练数据集学习，得到基本分类器 $G_m(x):X \rightarrow \{-1,+1\}$ ；
　(b) 计算 $G_m(x)$ 在训练数据集上的分类误差率 $e_m=P(G_m(x_i) \neq y_i)=\sum_{i=1}^{N}w_{mi}I(G_m(x_i) \neq y_i)$ ，其中 $I(x)$ 为指示函数；</description>
    </item>
    
    <item>
      <title>机器学习笔记-集成学习Bagging</title>
      <link>https://calxu.github.io/note/20200118_ml_bagging/</link>
      <pubDate>Sat, 18 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://calxu.github.io/note/20200118_ml_bagging/</guid>
      <description>工作也近一年半的时间，工作这段时间一直聚焦于业务，会调参懂业务基本可以解决工作中绝大部分业务问题，很多时候不需要深入理解理论。 最近闲下来有时间把机器学习的理论知识重新梳理学习下。 这篇笔记学习下机器学习中集成学习的一些知识。
集成学习（ensemble learning）是很多机器学习框架所应用到的一个策略。 目前比较有代表性的集成方式是Boosting 和 Bagging。 Boosting集成是每个基学习器间存在强依赖关系、必须串行生成，目前比较有代表性的工业界框架有AdaBoost、GBDT、XGBoost和LightGBM，其中后三者工业界比较常用；Bagging集成是每个基学习器间不需要存在依赖关系、可并行化，其中比较具有代表性的是随机森林（即 Random Forest），工业也比较常用。
这篇笔记主要基于周志华老师的《机器学习》西瓜书集成学习部分，聚焦在集成学习之Bagging方法。首先记录有放回采样的过程和特性；其次介绍集成学习Bagging方法，Bagging集成是建立在有放回采样的基础之上；最后介绍随机森林，随机森林是典型的基于Bagging集成的一个扩展变体。
有放回采样（bootstrap sampling） 有放回采样（bootstrap sampling）周志华的西瓜书里也把它称为“自助法”。给定包含 $m$ 个样本的数据集 $D$，我们对它进行采样产生数据集 $D&#39;$。 过程描述如下：每次随机从 $D$ 中挑选一个样本，将其拷贝放入 $D&#39;$ 中，然后再将该样本放回初始数据集 $D$ 中，该样本在下次采样时仍有可能被采到；这个过程重复执行 $m$ 次，就可得到包含 $m$ 个样本的数据集 $D&#39;$，以上便是有放回采样的结果。 $D$ 中有一部分样本会在 $D&#39;$ 中多次出现，而另一部分样本不出现。 样本在 $m$ 次采样中始终不被采到的概率是 $(1-\frac{1}{m})^m$ ，取极限得到 $\lim_{m\to +\infty}(1-\frac{1}{m})^m = \frac{1}{e} \approx 0.368$ ，即通过有放回采样，初始数据集中 $D$ 约有36.8% 的样本未出现在采样数据集 $D&#39;$ 中，而那部分样本可作测试集。
有放回采样在数据集较小，难以有效划分训练/测试集时很有用；同时，有放回采样可以从初始数据集中产生多个不同的训练集，这对集成学习等方法有很大的好处。
集成学习Bagging 欲得到泛化性能强的集成，集成中的个体学习器应尽可能相互独立；虽然个体学习器完全独立在现实任务中无法做到，但可以设法使基学习器尽可能具有较大的差异。 给定一个训练数据集，进行反复采样，可产生出若干个不同的子集，再从每个数据子集中训练出一个基学习器。 同时，为获得很好的集成，个体学习器不能太差，如果采样出的每个子集都完全不同，则每个基学习器只用到了一小部分训练数据，不足以有效学习。 所以反复地有放回采样（bootstrap sampling）是一种有效的方式，同时可产生相互有交叠的采样子集。
Bagging（Bootstrap AGGregatING）集成学习中采样即是采用有放回采样的方式进行采样的。 采样过程描述如下：给定包含 $m$ 个样本的数据集，我们先随机取出一个样本放入采集中，再把该样本放回初始数据集，使得下次采样时该样本仍有可能被选中，这样，经过 $m$ 次随机采样操作，我们得到含 $m$ 个样本的采样集。由有放回采样的性质得：初始训练集中约有63.2% (1-32.</description>
    </item>
    
  </channel>
</rss>